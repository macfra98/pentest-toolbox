from transformers import TFGPTJForCausalLM, GPT2Tokenizer

def generate_text(prompt, model_name='EleutherAI/gpt-neo-2.7B', max_length=50):
    # Load the model and tokenizer
    tokenizer = GPT2Tokenizer.from_pretrained(model_name)
    model = TFGPTJForCausalLM.from_pretrained(model_name)

    # Tokenize the prompt and generate text
    input_ids = tokenizer.encode(prompt, return_tensors='tf')
    gen_tokens = model.generate(input_ids, max_length=max_length)
    gen_text = tokenizer.decode(gen_tokens[0], skip_special_tokens=True)

    return gen_text

# Example usage
prompt = "A pentest was made which lasted 5 weeks, using the PTES model, ..."
print(generate_text(prompt))

